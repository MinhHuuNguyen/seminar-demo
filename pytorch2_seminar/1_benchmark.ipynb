{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9e2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch._dynamo\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from triton.testing import do_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec330ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c4d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57638b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(fn):\n",
    "    exec_time, prctl20, prctl80 = do_bench(fn, warmup=100, rep=1000)\n",
    "    return exec_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67303073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_improved_percent(exec_time, opt_exec_time):\n",
    "    avg_exec_time = (sum(exec_time) / len(exec_time))\n",
    "    avg_opt_exec_time = (sum(opt_exec_time) / len(opt_exec_time))\n",
    "    \n",
    "    print('avg_exec_time', avg_exec_time)\n",
    "    print('avg_opt_exec_time', avg_opt_exec_time)\n",
    "\n",
    "    return f'{round((avg_exec_time - avg_opt_exec_time) / avg_opt_exec_time * 100, 2)}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9a69d",
   "metadata": {},
   "source": [
    "# 1. Test ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1831fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(model, optimizer, device):\n",
    "    x = torch.randn(32, 3, 64, 64).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    out.sum().backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7d365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_only_forward(model, device):\n",
    "    x = torch.randn(32, 3, 64, 64).to(device)\n",
    "    out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3629d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nguyenhuuminh/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4272184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda:0'\n",
    "NUM_LOOP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11718fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time = [\n",
    "    run_benchmark(lambda: run_batch(model.to(device), optimizer, device))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "815de15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_exec_time 19.8604793548584\n",
      "avg_opt_exec_time 22.9171199798584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-13.34%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.reset() # Reset before compile again\n",
    "opt_model_default = torch.compile(model)\n",
    "\n",
    "opt_exec_time_default = [\n",
    "    run_benchmark(lambda: run_batch(opt_model_default.to(device), optimizer, device))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]\n",
    "\n",
    "cal_improved_percent(exec_time, opt_exec_time_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1312e25d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_exec_time 19.8604793548584\n",
      "avg_opt_exec_time 13.406208038330078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'48.14%'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.reset() # Reset before compile again\n",
    "\n",
    "opt_model_max = torch.compile(model, mode='max-autotune')\n",
    "\n",
    "opt_exec_time_max = [\n",
    "    run_benchmark(lambda: run_batch(opt_model_max.to(device), optimizer, device))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]\n",
    "\n",
    "cal_improved_percent(exec_time, opt_exec_time_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5b1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time = [\n",
    "    run_benchmark(lambda: run_only_forward(model.to(device), device))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fab7e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_exec_time 5.532671928405762\n",
      "avg_opt_exec_time 5.895167827606201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-6.15%'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.reset() # Reset before compile again\n",
    "\n",
    "opt_model_default = torch.compile(model)\n",
    "\n",
    "opt_exec_time_default = [\n",
    "    run_benchmark(lambda: run_only_forward(opt_model_default.to(device), device))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]\n",
    "\n",
    "cal_improved_percent(exec_time, opt_exec_time_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ad5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_exec_time 5.532671928405762\n",
      "avg_opt_exec_time 3.7201919555664062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'48.72%'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.reset() # Reset before compile again\n",
    "\n",
    "opt_model_max = torch.compile(model, mode='max-autotune')\n",
    "\n",
    "opt_exec_time_max = [\n",
    "    run_benchmark(lambda: run_only_forward(opt_model_max.to(device), device))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]\n",
    "\n",
    "cal_improved_percent(exec_time, opt_exec_time_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b628b3",
   "metadata": {},
   "source": [
    "# 2. Test Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beab4efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "input_ = tokenizer('This is a text to test the model', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e938d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "torch._dynamo.reset() # Reset before compile again\n",
    "\n",
    "opt_model = torch.compile(model, mode='max-autotune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddde2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_foward_transformers(model, input_):\n",
    "    output = model(**input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a64167e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time = [\n",
    "    run_benchmark(lambda: run_foward_transformers(model.to(device), input_.to(device)))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41e75115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_exec_time 9.825535774230957\n",
      "avg_opt_exec_time 1.7269760370254517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'468.94%'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_exec_time_max = [\n",
    "    run_benchmark(lambda: run_foward_transformers(opt_model.to(device), input_.to(device)))\n",
    "    for _ in range(NUM_LOOP)\n",
    "]\n",
    "\n",
    "cal_improved_percent(exec_time, opt_exec_time_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ece2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
